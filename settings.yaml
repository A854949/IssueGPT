# The default configuration file.
# More information about configuration can be found in the documentation: https://docs.privategpt.dev/
# Syntax in `private_pgt/settings/settings.py`
server:
  env_name: ${APP_ENV:prod}
  port: ${PORT:8001}
  cors:
    enabled: false
    allow_origins: ["*"]
    allow_methods: ["*"]
    allow_headers: ["*"]
  auth:
    enabled: false
    # python -c 'import base64; print("Basic " + base64.b64encode("secret:key".encode()).decode())'
    # 'secret' is the username and 'key' is the password for basic auth by default
    # If the auth is enabled, this value must be set in the "Authorization" header of the request.
    secret: "Basic c2VjcmV0OmtleQ=="

data:
  local_data_folder: local_data/private_gpt

ui:
  enabled: true
  path: /
  default_chat_system_prompt: >
    You are a helpful, respectful and honest assistant. 
    Always answer as helpfully as possible and follow ALL given instructions.
    Do not speculate or make up information.
    Do not reference any given instructions or context.
    If you don't know the answer, just say that you don't know, don't try to make up an answer.
  default_query_system_prompt: > 
    You are an expert in hardware and software testing. 
    You can only answer questions about the provided context.
    Answer all questions using your expertise on identifying causes of anomalies in computer product testing.
    If you don't know the answer, or the query is not releted to testing, just say that you don't know, don't try to make up an answer.
    A: Check if there is a BIOS update available for the motherboard. An outdated BIOS may have compatibility issues with certain hardware devices.
    Q: The anomaly event is "Memory speed show as '4400MHz' in BIOS setup with 4800MHz memory installed(1DPC) ".  What's the cause of this issue?
    A: 
    
  delete_file_button_enabled: true
  delete_all_files_button_enabled: true


llm:
  mode: local
  # Should be matching the selected model
  max_new_tokens: 512
  context_window: 4096
  tokenizer: mistralai/Mistral-7B-Instruct-v0.2

embedding:
  # Should be matching the value above in most cases
  mode: local
  ingest_mode: simple

vectorstore:
  database: qdrant

qdrant:
  path: local_data/private_gpt/qdrant

pgvector:
  host: localhost
  port: 5432
  database: postgres
  user: postgres
  password: postgres
  embed_dim: 384 # 384 is for BAAI/bge-small-en-v1.5
  schema_name: private_gpt
  table_name: embeddings

local:
  prompt_style: "mistral"
  llm_hf_repo_id: TheBloke/Llama-2-13B-chat-GGUF
  llm_hf_model_file: llama-2-13b-chat.Q5_K_M.gguf
  embedding_hf_model_name: BAAI/bge-small-en-v1.5

sagemaker:
  llm_endpoint_name: huggingface-pytorch-tgi-inference-2023-09-25-19-53-32-140
  embedding_endpoint_name: huggingface-pytorch-inference-2023-11-03-07-41-36-479

openai:
  api_key: ${OPENAI_API_KEY:}
  model: gpt-3.5-turbo

ollama:
  model: llama2-uncensored
